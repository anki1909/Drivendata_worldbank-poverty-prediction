{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A_hhold_train = pd.read_csv('../A_hhold_train.csv')\n",
    "A_indiv_train = pd.read_csv('../A_indiv_train.csv')\n",
    "A_hhold_test = pd.read_csv('../A_hhold_test.csv')\n",
    "A_indiv_test = pd.read_csv('../A_indiv_test.csv')\n",
    "B_hhold_train = pd.read_csv('../B_hhold_train.csv')\n",
    "B_indiv_train = pd.read_csv('../B_indiv_train.csv')\n",
    "B_hhold_test = pd.read_csv('../B_hhold_test.csv')\n",
    "B_indiv_test = pd.read_csv('../B_indiv_test.csv')\n",
    "C_hhold_train = pd.read_csv('../C_hhold_train.csv')\n",
    "C_indiv_train = pd.read_csv('../C_indiv_train.csv')\n",
    "C_hhold_test = pd.read_csv('../C_hhold_test.csv')\n",
    "C_indiv_test = pd.read_csv('../C_indiv_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "iid\n",
      "OdXpbPGJ\n",
      "ukWqmeSS\n",
      "poor\n",
      "id\n",
      "iid\n",
      "BoxViLPz\n",
      "qlLzyqpP\n",
      "unRAgFtX\n",
      "TJGiunYp\n",
      "WmKLEUcd\n",
      "poor\n",
      "DYgxQeEi\n",
      "jfsTwowc\n",
      "MGfpfHam\n",
      "esHWAAyG\n",
      "DtcKwIEv\n",
      "ETgxnJOM\n",
      "gKsBCLMY\n",
      "TZDgOhYY\n",
      "sWElQwuC\n",
      "jzBRbsEG\n",
      "CLTXEwmz\n",
      "WqEZQuJP\n",
      "dnmwvCng\n",
      "DSttkpSI\n",
      "sIiSADFG\n",
      "uDmhgsaQ\n",
      "hdDTwJhQ\n",
      "AJgudnHB\n",
      "iZhWxnWa\n",
      "fyfDnyQk\n",
      "wJthinfa\n",
      "nxAFXxLQ\n",
      "mAeaImix\n",
      "HZqPmvkr\n",
      "ulQCDoYe\n",
      "tzYvQeOb\n",
      "NfpXxGQk\n",
      "id\n",
      "iid\n",
      "XKQWlRjk\n",
      "vWNISgEA\n",
      "bsMfXBld\n",
      "XKyOwsRR\n",
      "CgAkQtOd\n",
      "poor\n"
     ]
    }
   ],
   "source": [
    "A_indiv_train_new = A_indiv_train[['id','iid']]\n",
    "for i in A_indiv_train.columns:\n",
    "    if (i != 'id') & (i!='iid') & (A_indiv_train[i].dtype == 'object'):\n",
    "        k = pd.get_dummies(A_indiv_train[i])\n",
    "        A_indiv_train_new = pd.concat((A_indiv_train_new,k),axis=1)\n",
    "    else:\n",
    "        print i\n",
    "A_indiv_train_new = A_indiv_train_new.groupby('id').agg('sum').reset_index().drop('iid',axis=1)\n",
    "B_indiv_train_new = B_indiv_train[['id','iid']]\n",
    "for i in B_indiv_train.columns:\n",
    "    if (i != 'id') & (i!='iid') & (B_indiv_train[i].dtype == 'object'):\n",
    "        k = pd.get_dummies(B_indiv_train[i])\n",
    "        B_indiv_train_new = pd.concat((B_indiv_train_new,k),axis=1)\n",
    "    else:\n",
    "        print i\n",
    "B_indiv_train_new = B_indiv_train_new.groupby('id').agg('sum').reset_index().drop('iid',axis=1)\n",
    "\n",
    "C_indiv_train_new = C_indiv_train[['id','iid']]\n",
    "for i in C_indiv_train.columns:\n",
    "    if (i != 'id') & (i!='iid') & (C_indiv_train[i].dtype == 'object'):\n",
    "        k = pd.get_dummies(C_indiv_train[i])\n",
    "        C_indiv_train_new = pd.concat((C_indiv_train_new,k),axis=1)\n",
    "    else:\n",
    "        print i\n",
    "C_indiv_train_new = C_indiv_train_new.groupby('id').agg('sum').reset_index().drop('iid',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A_indiv_test_new = A_indiv_test[['id','iid']]\n",
    "for i in A_indiv_test.columns:\n",
    "    if (i != 'id') & (i!='iid') & (A_indiv_test[i].dtype == 'object'):\n",
    "        k = pd.get_dummies(A_indiv_test[i])\n",
    "        A_indiv_test_new = pd.concat((A_indiv_test_new,k),axis=1)\n",
    "A_indiv_test_new = A_indiv_test_new.groupby('id').agg('sum').reset_index().drop('iid',axis=1)\n",
    "\n",
    "B_indiv_test_new = B_indiv_test[['id','iid']]\n",
    "for i in B_indiv_test.columns:\n",
    "    if (i != 'id') & (i!='iid') & (B_indiv_test[i].dtype == 'object'):\n",
    "        k = pd.get_dummies(B_indiv_test[i])\n",
    "        B_indiv_test_new = pd.concat((B_indiv_test_new,k),axis=1)\n",
    "B_indiv_test_new = B_indiv_test_new.groupby('id').agg('sum').reset_index().drop('iid',axis=1)\n",
    "\n",
    "C_indiv_test_new = C_indiv_test[['id','iid']]\n",
    "for i in C_indiv_test.columns:\n",
    "    if (i != 'id') & (i!='iid') & (C_indiv_test[i].dtype == 'object'):\n",
    "        k = pd.get_dummies(C_indiv_test[i])\n",
    "        C_indiv_test_new = pd.concat((C_indiv_test_new,k),axis=1)\n",
    "C_indiv_test_new = C_indiv_test_new.groupby('id').agg('sum').reset_index().drop('iid',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A_hhold_train = A_hhold_train.merge(A_indiv_train_new,on='id',how='left')\n",
    "B_hhold_train = B_hhold_train.merge(B_indiv_train_new,on='id',how='left')\n",
    "C_hhold_train = C_hhold_train.merge(C_indiv_train_new,on='id',how='left')\n",
    "\n",
    "A_hhold_test = A_hhold_test.merge(A_indiv_test_new,on='id',how='left')\n",
    "B_hhold_test = B_hhold_test.merge(B_indiv_test_new,on='id',how='left')\n",
    "C_hhold_test = C_hhold_test.merge(C_indiv_test_new,on='id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [i for i in A_hhold_train.columns if i in A_hhold_test.columns ]\n",
    "a.remove('id')\n",
    "b = [i for i in B_hhold_train.columns if i in B_hhold_test.columns ]\n",
    "b.remove('id')\n",
    "c = [i for i in C_hhold_train.columns if i in C_hhold_test.columns ]\n",
    "c.remove('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A_poor  = A_hhold_train.poor\n",
    "A_id = A_hhold_test.id\n",
    "B_poor  = B_hhold_train.poor\n",
    "B_id = B_hhold_test.id\n",
    "C_poor  = C_hhold_train.poor\n",
    "C_id = C_hhold_test.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A_hhold_train = A_hhold_train[a]\n",
    "A_hhold_test = A_hhold_test[a]\n",
    "B_hhold_train = B_hhold_train[b]\n",
    "B_hhold_test = B_hhold_test[b]\n",
    "C_hhold_train = C_hhold_train[c]\n",
    "C_hhold_test = C_hhold_test[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble, preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "A_hhold_train.replace(np.nan,-1,inplace=True)\n",
    "A_hhold_test.replace(np.nan,-1,inplace=True)\n",
    "text_columns = []\n",
    "for f in A_hhold_train.columns:\n",
    "    if A_hhold_train[f].dtype == 'object':  \n",
    "        text_columns.append(f)            \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(A_hhold_train[f].values) + list(A_hhold_test[f].values))\n",
    "        A_hhold_train[f] = lbl.transform(list(A_hhold_train[f].values))\n",
    "        A_hhold_test[f] = lbl.transform(list(A_hhold_test[f].values)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble, preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "B_hhold_train.replace(np.nan,-1,inplace=True)\n",
    "B_hhold_test.replace(np.nan,-1,inplace=True)\n",
    "text_columns = []\n",
    "for f in B_hhold_train.columns:\n",
    "    if B_hhold_train[f].dtype == 'object':  \n",
    "        text_columns.append(f)            \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(B_hhold_train[f].values) + list(B_hhold_test[f].values))\n",
    "        B_hhold_train[f] = lbl.transform(list(B_hhold_train[f].values))\n",
    "        B_hhold_test[f] = lbl.transform(list(B_hhold_test[f].values)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble, preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "C_hhold_train.replace(np.nan,-1,inplace=True)\n",
    "C_hhold_test.replace(np.nan,-1,inplace=True)\n",
    "text_columns = []\n",
    "for f in C_hhold_train.columns:\n",
    "    if C_hhold_train[f].dtype == 'object':  \n",
    "        text_columns.append(f)            \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(C_hhold_train[f].values) + list(C_hhold_test[f].values))\n",
    "        C_hhold_train[f] = lbl.transform(list(C_hhold_train[f].values))\n",
    "        C_hhold_test[f] = lbl.transform(list(C_hhold_test[f].values)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    }
   ],
   "source": [
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.LGBMClassifier(objective='binary',\n",
    "                        num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=400,max_depth=8)\n",
    "gbm.fit(A_hhold_train, A_poor)\n",
    "pred = gbm.predict_proba(A_hhold_test)[:,1]\n",
    "subA = pd.DataFrame({'id':A_id,'country':'A','poor':pred})[['id','country','poor']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    }
   ],
   "source": [
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.LGBMClassifier(objective='binary',\n",
    "                        num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=400,max_depth=8)\n",
    "gbm.fit(B_hhold_train, B_poor)\n",
    "pred = gbm.predict_proba(B_hhold_test)[:,1]\n",
    "subB = pd.DataFrame({'id':B_id,'country':'B','poor':pred})[['id','country','poor']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    }
   ],
   "source": [
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.LGBMClassifier(objective='binary',\n",
    "                        num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=400,max_depth=8)\n",
    "gbm.fit(C_hhold_train, C_poor)\n",
    "pred = gbm.predict_proba(C_hhold_test)[:,1]\n",
    "subC = pd.DataFrame({'id':C_id,'country':'C','poor':pred})[['id','country','poor']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat((subA,subB,subC)).to_csv('lol.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = pd.concat((subA,subB,subC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k1 = pd.read_csv('lgbm123.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8832, 3), (8832, 3))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1.shape,k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k['poor'] = 0.5*k1.poor.values + 0.5*k.poor.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k.to_csv('lol1.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
